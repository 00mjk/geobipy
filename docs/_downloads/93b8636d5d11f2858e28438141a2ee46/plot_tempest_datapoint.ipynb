{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Tempest Datapoint Class\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "There are three ways in which to create a time domain datapoint\n\n1) `Instantiating a time domain datapoint`\n\n2) `Reading a datapoint from a file`\n\n3) `Obtaining a datapoint from a dataset`\n\nOnce instantiated, see `Using a time domain datapoint`\n\nCredits:\nWe would like to thank Ross Brodie at Geoscience Australia for his airborne time domain forward modeller\nhttps://github.com/GeoscienceAustralia/ga-aem\n\nFor ground-based time domain data, we are using Dieter Werthmuller's python package Empymod\nhttps://empymod.github.io/\n\nThanks to Dieter for his help getting Empymod ready for incorporation into GeoBIPy\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from os.path import join\nimport numpy as np\nimport h5py\nimport matplotlib.pyplot as plt\nfrom geobipy import hdfRead\nfrom geobipy import Waveform\nfrom geobipy import SquareLoop, CircularLoop\nfrom geobipy import butterworth\nfrom geobipy import TdemSystem\nfrom geobipy import TempestData\n# from geobipy import TemDataPoint\nfrom geobipy import Model1D\nfrom geobipy import StatArray\nfrom geobipy import Distribution\n\ndataFolder = \"..//supplementary//Data//\"\n# dataFolder = \"source//examples//supplementary//Data\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Obtaining a datapoint from a dataset\nMore often than not, our observed data is stored in a file on disk.\nWe can read in a dataset and pull datapoints from it.\n\nFor more information about the time domain data set, see `Time domain dataset`\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# The data file name\ndataFile = dataFolder + 'Tempest.nc'\n# The EM system file name\nsystemFile = dataFolder + 'Tempest.stm'\n\n\n# Prepare the dataset so that we can read a point at a time.\nDataset = TempestData._initialize_sequential_reading(dataFile, systemFile)\n# Get a datapoint from the file.\ntdp = Dataset._read_record(0)\n\n\nplt.figure()\ntdp.plot()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Using a time domain datapoint\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can define a 1D layered earth model, and use it to predict some data\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "par = StatArray(np.r_[1/50.0, 1/100.0, 1/1000.0, 1/5.0, 1/1000.0, 1/800.0], \"Conductivity\", \"$\\frac{S}{m}$\")\nmod = Model1D(edges=np.r_[0, 20.0, 50.0, 100.0, 150.0, 250.0, np.inf], parameters=par)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Forward model the data\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "tdp.forward(mod)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "plt.figure()\nplt.subplot(121)\n_ = mod.pcolor(transpose=True)\nplt.subplot(122)\n_ = tdp.plot()\n_ = tdp.plotPredicted()\nplt.tight_layout()\nplt.suptitle('Model and response')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "plt.figure()\ntdp.plotDataResidual(xscale='log')\nplt.title('data residual')\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Compute the sensitivity matrix for a given model\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "J = tdp.sensitivity(mod)\nplt.figure()\n_ = np.abs(J).pcolor(equalize=True, log=10, flipY=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Attaching statistical descriptors to the datapoint\n\nSet relative errors for the primary fields, and secondary fields.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "tdp.relErr = np.r_[0.01, 0.05]\n\n# Set the additive errors for\ntdp.addErr = np.hstack([[0.011474, 0.012810, 0.008507, 0.005154, 0.004742, 0.004477, 0.004168, 0.003539, 0.003352, 0.003213, 0.003161, 0.003122, 0.002587, 0.002038, 0.002201],\n                       [0.007383, 0.005693, 0.005178, 0.003659, 0.003426, 0.003046, 0.003095, 0.003247, 0.002775, 0.002627, 0.002460, 0.002178, 0.001754, 0.001405, 0.001283]])\n# Define a multivariate log normal distribution as the prior on the predicted data.\ntdp.predictedData.prior = Distribution('MvLogNormal', tdp.data[tdp.active], tdp.std[tdp.active]**2.0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This allows us to evaluate the likelihood of the predicted data\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print(tdp.likelihood(log=True))\n# Or the misfit\nprint(tdp.dataMisfit())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Plot the misfits for a range of half space conductivities\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "plt.figure()\nplt.subplot(1, 2, 1)\n_ = tdp.plotHalfSpaceResponses(-6.0, 4.0, 200)\nplt.title(\"Halfspace responses\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can perform a quick search for the best fitting half space\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "halfspace = tdp.find_best_halfspace()\nprint('Best half space conductivity is {} $S/m$'.format(halfspace.par))\nplt.subplot(1, 2, 2)\n_ = tdp.plot()\n_ = tdp.plotPredicted()\n\nplt.figure()\ntdp.plot_secondary_field()\ntdp.plot_predicted_secondary_field()\n\n# ################################################################################\n# # We can attach priors to the height of the datapoint,\n# # the relative error multiplier, and the additive error noise floor\n\n# Define the distributions used as priors.\nheightPrior = Distribution('Uniform', min=np.float64(tdp.z) - 1.0, max=np.float64(tdp.z) + 1.0)\nrelativePrior = Distribution('Uniform', min=np.r_[0.01, 0.01], max=np.r_[0.5, 0.5])\npitchPrior = Distribution('Uniform', min=tdp.transmitter.pitch - 5.0, max=tdp.transmitter.pitch + 5.0)\n# additivePrior = Distribution('Uniform', min=np.r_[1e-12, 1e-13], max=np.r_[1e-10, 1e-11], log=True)\ntdp.set_priors(height_prior=heightPrior, relative_error_prior=relativePrior, transmitter_pitch_prior=pitchPrior)#, additive_error_prior=additivePrior)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In order to perturb our solvable parameters, we need to attach proposal distributions\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "heightProposal = Distribution('Normal', mean=tdp.z, variance = 0.01)\nrelativeProposal = Distribution('MvNormal', mean=tdp.relErr, variance=2.5e-4)\ntransmitter_pitch_proposal = Distribution('Normal', mean=tdp.transmitter.pitch, variance = 0.01)\n# additiveProposal = Distribution('MvLogNormal', mean=tdp.addErr, variance=2.5e-3, linearSpace=True)\ntdp.set_proposals(heightProposal, relativeProposal, transmitter_pitch_proposal=transmitter_pitch_proposal)#, additiveProposal)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "With priorss set we can auto generate the posteriors\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "tdp.set_posteriors()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Perturb the datapoint and record the perturbations\nNote we are not using the priors to accept or reject perturbations.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "for i in range(10):\n    tdp.perturb()\n    tdp.updatePosteriors()\n\nplt.show()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}