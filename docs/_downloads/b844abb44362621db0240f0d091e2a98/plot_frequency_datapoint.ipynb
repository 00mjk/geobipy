{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Frequency domain datapoint\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "There are two ways in which to create a frequency domain datapoint,\n\n1) `Instantiating a frequency domain data point`\n\n2) `Obtaining a datapoint from a dataset`\n\nOnce instantiated, see `Using a frequency domain datapoint`\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from os.path import join\nimport numpy as np\nimport h5py\nimport matplotlib.pyplot as plt\nfrom geobipy import hdfRead\nfrom geobipy import CircularLoop\nfrom geobipy import FdemSystem\nfrom geobipy import FdemData\nfrom geobipy import FdemDataPoint\nfrom geobipy import Model1D\nfrom geobipy import StatArray\nfrom geobipy import Distribution"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Instantiating a frequency domain data point\n\nTo instantiate a frequency domain datapoint we need to define some\ncharacteristics of the acquisition system.\n\nWe need to define the frequencies in Hz of the transmitter,\nand the geometery of the loops used for each frequency.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "frequencies = np.asarray([380.0, 1776.0, 3345.0, 8171.0, 41020.0, 129550.0])\n\ntransmitterLoops = [CircularLoop(orient='z'),     CircularLoop(orient='z'),\n                    CircularLoop('x', moment=-1), CircularLoop(orient='z'),\n                    CircularLoop(orient='z'),     CircularLoop(orient='z')]\n\nreceiverLoops    = [CircularLoop(orient='z', x=7.93),    CircularLoop(orient='z', x=7.91),\n                    CircularLoop('x', moment=1, x=9.03), CircularLoop(orient='z', x=7.91),\n                    CircularLoop(orient='z', x=7.91),    CircularLoop(orient='z', x=7.89)]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now we can instantiate the system.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "fds = FdemSystem(frequencies, transmitterLoops, receiverLoops)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "And use the system to instantiate a datapoint\n\nNote the extra arguments that can be used to create the data point.\ndata is for any observed data one might have, while std are the estimated standard\ndeviations of those observed data.\n\nDefine some in-phase then quadrature data for each frequency.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "data = np.r_[145.3, 435.8, 260.6, 875.1, 1502.7, 1516.9,\n             217.9, 412.5, 178.7, 516.5, 405.7, 255.7]\n\nfdp = FdemDataPoint(x=0.0, y=0.0, z=30.0, elevation=0.0,\n                    data=data, std=None, predictedData=None,\n                    system=fds, lineNumber=0.0, fiducial=0.0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "plt.figure()\n_ = fdp.plot()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Obtaining a datapoint from a dataset\n\nMore often than not, our observed data is stored in a file on disk.\nWe can read in a dataset and pull datapoints from it.\n\nFor more information about the frequency domain data set see `Frequency domain dataset`\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Set some paths and file names\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "dataFolder = \"..//supplementary//Data//\"\n# The data file name\ndataFile = dataFolder + 'Resolve2.txt'\n# The EM system file name\nsystemFile = dataFolder + 'FdemSystem2.stm'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Initialize and read an EM data set\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "D = FdemData.read_csv(dataFile,systemFile)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Get a data point from the dataset\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "fdp = D.datapoint(0)\nplt.figure()\n_ = fdp.plot()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Using a datapoint\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can define a 1D layered earth model, and use it to predict some data\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "nCells = 19\npar = StatArray(np.linspace(0.01, 0.1, nCells), \"Conductivity\", \"$\\frac{S}{m}$\")\nthk = StatArray(np.ones(nCells) * 10.0)\nthk[-1] = np.inf\nmod = Model1D(nCells = nCells, parameters=par, widths=thk)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Forward model the data\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "fdp.forward(mod)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "plt.figure()\nplt.subplot(121)\n_ = mod.pcolor()\nplt.subplot(122)\n_ = fdp.plotPredicted()\nplt.tight_layout()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Compute the sensitivity matrix for a given model\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "J = fdp.sensitivity(mod)\nplt.figure()\n_ = np.abs(J).pcolor(equalize=True, log=10, flipY=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Attaching statistical descriptors to the datapoint\n\nDefine a multivariate log normal distribution as the prior on the predicted data.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "fdp.predictedData.set_prior('MvLogNormal', fdp.data[fdp.active], fdp.std[fdp.active]**2.0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This allows us to evaluate the likelihood of the predicted data\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print(fdp.likelihood(log=True))\n# Or the misfit\nprint(fdp.dataMisfit())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can perform a quick search for the best fitting half space\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "halfspace = fdp.FindBestHalfSpace()\nprint('Best half space conductivity is {} $S/m$'.format(halfspace.par))\nplt.figure()\n_ = fdp.plot()\n_ = fdp.plotPredicted()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Compute the misfit between observed and predicted data\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print(fdp.dataMisfit())\n\n\n# Set values of relative and additive error for both systems.\nfdp.relErr = 0.05\nfdp.addErr = 10.0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Plot the misfits for a range of half space conductivities\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "plt.figure()\n_ = fdp.plotHalfSpaceResponses(-6.0, 4.0, 200)\n\nplt.title(\"Halfspace responses\");\n\n# ################################################################################\n# # We can attach priors to the height of the datapoint,\n# # the relative error multiplier, and the additive error noise floor\n\n\n# # Define the distributions used as priors.\n# heightPrior = Distribution('Uniform', min=np.float64(fdp.z) - 2.0, max=np.float64(fdp.z) + 2.0)\n# relativePrior = Distribution('Uniform', min=0.01, max=0.5)\n# additivePrior = Distribution('Uniform', min=5, max=15)\n# fdp.set_priors(height_prior=heightPrior, relative_error_prior=relativePrior, additive_error_prior=additivePrior)\n\n# ################################################################################\n# # In order to perturb our solvable parameters, we need to attach proposal distributions\n# heightProposal = Distribution('Normal', mean=fdp.z, variance = 0.01)\n# relativeProposal = Distribution('MvNormal', mean=fdp.relErr, variance=2.5e-7)\n# additiveProposal = Distribution('MvLogNormal', mean=fdp.addErr, variance=1e-4)\n# fdp.setProposals(heightProposal, relativeProposal, additiveProposal)\n\n# ################################################################################\n# # With priors set we can auto generate the posteriors\n# fdp.setPosteriors()\n\n# # Perturb the datapoint and record the perturbations\n# for i in range(10000):\n#     fdp.forward(mod)\n#     fdp.perturb(True, True, True, False)\n#     fdp.updatePosteriors()\n\n# ################################################################################\n# # Plot the posterior distributions\n# # fig = plt.figure()\n# # gs = fig.add_gridspec(nrows=1, ncols=1)\n# # ax = fdp.init_posterior_plots(gs[0, 0])\n# # fig.tight_layout()\n\n# # fdp.plot_posteriors(axes=ax, best=fdp)\n\n# import h5py\n# with h5py.File('fdp.h5', 'w') as f:\n#     fdp.toHdf(f, 'fdp', withPosterior=True)\n\n# with h5py.File('fdp.h5', 'r') as f:\n#     fdp1 = FdemDataPoint.fromHdf(f['fdp'])\n\nprint('done')\nplt.show()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}